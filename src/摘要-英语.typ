#import "../uestc-thesis-template/lib.typ":*

Large Language Models (LLMs) highly rely on high-quality training data for performance improvement. However, currently, the training of LLMs is facing a severe data supply crisis. This crisis stems from multiple contradictions: the exponential demand for model capacity expansion, while the annual increment of digital texts globally only experiences linear growth; network texts have issues such as noise interference, semantic biases, and lack of annotation, and data cleaning requires a large amount of computing power; the training set overly depends on web content, and the proportion of corpus in professional fields is insufficient.

In response to the above problems, this paper proposes an automated question-answering dataset generation framework, MiniRAG-QAG, based on the Retrieval Augmented Generation (RAG) technology. This framework aims to break through the physical limitations of traditional data collection through a closed-loop mechanism of "data synthesis - quality verification - feedback optimization" and provide an efficient and compliant high-quality data source for LLM training.

In specific implementation, this study focuses on three core aspects. Firstly, a RAG enhancement framework that integrates a dynamic chunking and hybrid retrieval strategy is designed. Through hierarchical semantic segmentation, namely paragraph-level and content type-level segmentation, and a hybrid retrieval model that combines BGE-M3 vector retrieval and BM25 keyword retrieval with weighting, and uses BGE-Reranker for relevance re-ranking, the accuracy of knowledge retrieval and context adaptability are significantly improved. Secondly, a comprehensive multi-dimensional evaluation system is constructed, covering dimensions such as relevance, unknowability, integrity, accuracy, and rationality. At the same time, the innovative introduction of dynamic threshold calculation and evidence coverage quantification methods effectively solves the problem that traditional evaluation models overly rely on manual annotation. Experiments show that MiniRAG-QAG performs excellently on the UTD24 dataset, and the comprehensive score of the generated question-answering pairs reaches 0.7427, significantly better than mainstream models. Among them, the accuracy is 0.6935, which is 9.37% higher than that of the second-best model. In addition, this study constructs the UTD24_QA dataset based on 17,542 academic documents in the field of economics and management, which contains 170,226 groups of QA data, and a corresponding evaluation benchmark, UTD24_QA_5k-benchmark, is established, filling the gap in the LLM dataset in the professional field of economics and management.

To promote the implementation and application of the technology, this study also develops an integrated QAG system. This system integrates the Streamlit and LangChain technology stacks and realizes full-process visual operation. The system supports intelligent document analysis, dynamic parameter configuration, multi-model collaborative generation, and dataset version management, and ensures the traceability of the data flow through a metadata-driven architecture. This achievement not only provides a compliant data generation solution for data-sensitive fields such as healthcare and finance but also, through the innovative paradigm of "training models with models", provides a feasible technical path for the evolution of artificial intelligence from a "data-dependent" type to an "intelligence-endogenous" type.  