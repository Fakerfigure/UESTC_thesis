#import "../uestc-thesis-template/lib.typ":*

= 总结与展望


== 总结  
本研究针对大型语言模型（LLM）训练面临的高质量数据供给危机，提出了基于检索增强生成（RAG）技术的自动化问答数据集生成框架 MiniRAG-QAG，通过“数据合成-质量验证-反馈优化”闭环机制，为LLM提供高效合规的数据源，推动AI从“数据依赖型”向“智能内生型”演进。  

===  核心研究内容与创新  
1. 混合检索增强框架设计 
   构建动态分块与混合检索策略，通过段落级与内容类型级的分层语义切分，结合BGE-M3向量检索与BM25关键词检索，并利用BGE-Reranker进行相关性重排序，显著提升知识检索的准确性与上下文适配性。该设计有效解决了传统RAG在专业文献处理中存在的语义断层与检索偏差问题，为问答对生成奠定了扎实的知识基础。  

2. 多维度评估体系构建
   提出涵盖相关性、不可知性、完整性、准确性与合理性的评估框架，创新性引入动态阈值计算与证据覆盖度量化方法，突破传统评估对人工标注的依赖。实验表明，MiniRAG-QAG在UTD24数据集上综合得分达0.7427，全面领跑，其中准确性（0.6935）较次优模型分别提升9.37%，验证了评估体系的科学性与有效性。  

3. 领域数据集与系统落地
   基于17542篇经管领域学术文献构建UTD24_QA数据集（含170226组问答对），并配套建立UTD24_QA_5k-benchmark评测基准，填补了LLM在专业领域数据集的空白。开发集成Streamlit与LangChain的一体式QAG系统，实现文献解析、参数配置、模型协同生成与数据集管理的全流程可视化，为医疗、金融等数据敏感领域提供合规化数据生成方案，推动技术落地应用。  

=== 研究价值与贡献  
本研究不仅在技术层面突破了传统数据采集的物理限制，通过RAG与LLM的深度融合实现了高质量问答数据的自动化生成，更在范式层面探索了“以模型养模型”的创新路径。UTD24_QA数据集与评估基准为领域化LLM训练提供了标准化资源，可视化系统降低了技术使用门槛，具有显著的学术价值与产业应用潜力。  


== 展望  
- 技术优化与范式创新  
未来研究可聚焦"多模态检索增强"，将文本、图表、公式等异构数据纳入检索体系，提升复杂知识场景下的问答生成能力；探索"动态自适应评估模型"，结合强化学习动态调整评估指标权重，进一步优化质量筛选效率。此外，可尝试将框架与因果推理、常识知识相结合，生成具备逻辑深度的问答对，推动LLM从“信息复述”向“知识推理”升级。  

- 领域拓展与生态构建  
当前UTD24_QA数据集聚焦经管领域，后续可将框架扩展至医疗、法律、教育等专业领域，构建跨学科的高质量数据集体系。同时，建议建立"开源数据生成社区"，通过众包机制汇聚多领域文献，形成覆盖全学科的动态更新数据集，促进AI模型的领域适配性研究。在系统层面，可开发API接口与云服务平台，支持企业级用户自定义数据生成流程，推动技术普惠。