#import "../uestc-thesis-template/lib.typ":*

= 绪论
== 研究背景

近年来，人工智能领域的技术突破与大型语言模型（Large Language Model, LLM）的性能跃升形成显著正相关。LLM的演进路径呈现出"数据驱动型创新"特征：相较于模型架构的优化，高质量训练数据的规模与质量对模型性能提升具有决定性作用。以OpenAI的系列模型为例，GPT-3在模型架构仅进行微调（参数规模扩大至1750亿）的情况下，通过构建包含Common Crawl、WebText2等来源的45TB原始数据集，并经过多阶段质量过滤形成570GB有效训练数据（占原始数据1.27%），最终实现跨任务的零样本学习能力 @DBLP:journals。这种"数据规模-质量"双维度提升范式在ChatGPT中得到延续，其通过引入人类反馈强化学习（RLHF）机制生成高质量标记数据，使模型展现出类人的对话逻辑与知识推理能力。

然而，当前LLM训练正面临严峻的数据供给危机。据Epoch研究所预测，按照现有技术路线，互联网高质量文本数据将于2026年达到理论开采极限 @villalobos2022will。这种数据供需失衡源于三重结构性矛盾：其一，模型容量扩张呈现指数级需求，GPT-4等前沿模型训练数据量已达千亿token量级，而全球数字化文本年增量仅维持线性增长；其二，数据质量瓶颈凸显，网络文本普遍存在噪声干扰、语义偏见及标注缺失等问题，需耗费大量算力进行数据清洗；其三，数据多样性持续衰减，现有训练集过度依赖网页内容（占比超82%），专业领域语料（如学术论文、法律文书）占比不足7% @DBLP:journals。

在此背景下，构建基于LLM的自动化问答数据集生成框架具有重要理论价值与实践意义。从技术演进维度，该框架可通过"数据合成-质量验证-反馈优化"的闭环机制，突破传统数据采集的物理边界。从产业应用层面，该方法能有效缓解数据短缺对模型迭代的制约，尤其可为医疗、金融等数据敏感领域提供合规化数据供给方案。更深远的意义在于，这种"以模型养模型"的范式创新或将重塑AI研发范式，推动人工智能从"数据依赖型"向"智能内生型"阶段演进。

// == 研究现状

// 问题生成（Question Generation, QG）和问题回答生成（Question Answer Generation, QAG）是自然语言处理中备受关注的研究领域 @Lin_2021_12 @9514975。
// QAG旨在从给定的上下文（例如段落）中自动生成问题和答案对，已被广泛应用于数据增强、信息检索和教育等领域 @ushio2023empirical @yadav2024explicitdiversityconditionseffective  @pham2024towards  @yao2022aisturnaskhumans。

// // *QAG的基本方法：* 

// 早期的QAG研究通常将问题生成和答案抽取作为两个独立的任务进行处理 @Lin_2021_12 。然而，这种分离的方式可能导致生成的问题与答案不匹配。目前主流的QAG方法主要分为以下几类：
// - 基于规则的方法 @mitkov2003computer @heilman2010good ：该方法依赖于人工设计的规则和模板来生成问题。这种方法简单直接，但泛化能力较弱，难以处理复杂场景。
// - 基于深度学习的方法：该方法利用深度神经网络，如循环神经网络（RNN）、Transformer等，直接从文本中学习问题生成的模式。近年来，随着预训练语言模型（PLM）的兴起，基于PLM的QAG方法成为主流。

// // *基于大型语言模型的QAG：*

// 大型语言模型（LLM）如 GPT-4 @achiam2023gpt、DeepSeek @liu2024deepseek 、Qwen @bai2023qwen，在自然语言处理领域表现出强大的能力。通过在海量数据上进行预训练，LLM能够学习到丰富的语言知识和上下文信息，从而在QAG任务中表现出色 @yue2025surveylargelanguagemodel 。

// - 微调：一种常见的做法是直接在QAG数据集上微调LLM，使其学习从文本生成问题和答案 @ushio2023empirical @ushio2023empiricalcomparisonlmbasedquestion 。这种方法简单有效，但需要大量的标注数据。
// - 检索增强生成（RAG）：RAG方法通过检索外部知识来增强LLM的知识储备，从而提高QAG的质量 @xu2025simragselfimprovingretrievalaugmentedgeneration @chu2025enhancingllmbasedshortanswer @liao2024awakening @arefeen2024leancontext 。RAG可以缓解LLM的知识缺失问题，并提高生成答案的准确性。

// Yuwei Wan等人提出了SciQAG框架 @wan2024sciqagframeworkautogeneratedscience，用于自动生成高质量的科学问题与答案对。SciQAG框架包含一个QA生成器和一个QA评估器，它们协同工作，从科学论文中提取多样且具有研究水平的问题和答案，然而该框架高度依赖大模型自身的能力，且产生的QA在不可知性的表现上差强人意。

== 研究现状<related>

问题生成（Question Generation, QG）和问题回答生成（Question Answer Generation, QAG）是自然语言处理领域中备受关注的研究方向 @Lin_2021_12 @9514975。QAG旨在从给定的上下文（如段落）中自动生成语义一致且具有信息量的问题与答案对，已被广泛应用于数据增强、信息检索及教育等领域 @ushio2023empirical @yadav2024explicitdiversityconditionseffective @pham2024towards @yao2022aisturnaskhumans。

// QAG的基本方法：

早期的QAG研究通常将问题生成与答案抽取作为两个相互独立的任务分别处理 @Lin_2021_12 。然而，这种分离式建模方式可能导致生成的问题与答案之间缺乏一致性或语义关联性。目前，主流的QAG方法主要可分为以下两类：

- 基于规则的方法 @mitkov2003computer @heilman2010good ：该类方法依赖人工设计的语言规则与模板进行问题生成。尽管实现简单且可控性强，但其泛化能力有限，难以应对复杂多变的语言结构。
- 基于深度学习的方法：该类方法利用循环神经网络（RNN）、Transformer等深度神经网络模型，直接从文本中端到端地学习问题生成模式 @ushio2023empiricalcomparisonlmbasedquestion 。
// 近年来，随着预训练语言模型（Pretrained Language Models, PLMs）的发展，基于PLM的QAG方法逐渐成为研究主流。
// 基于大型语言模型的QAG：

近年来，大规模预训练语言模型（Large Language Models, LLMs），如 GPT-4 @achiam2023gpt、DeepSeek @liu2024deepseek 以及 Qwen @bai2023qwen，在多项自然语言处理任务中展现出卓越的语言理解与生成能力。这些模型通过在海量语料上进行预训练，能够捕捉丰富的语言知识与上下文依赖关系，因而在QAG任务中也表现出优异性能 @yue2025surveylargelanguagemodel 。

当前，基于LLMs的QAG方法主要包括以下两类策略：

- 微调（Fine-tuning） ：一种常见做法是在特定领域的QAG数据集上对LLM进行微调，以适配具体任务需求 @ushio2023empirical @ushio2023empiricalcomparisonlmbasedquestion 。该方法实现简便且效果显著，但高度依赖大量高质量标注数据。
- 检索增强生成（Retrieval-Augmented Generation, RAG） ：RAG方法通过引入外部知识库中的相关信息，增强LLM在生成过程中的知识支撑，从而提升生成结果的质量与准确性 @xu2025simragselfimprovingretrievalaugmentedgeneration @chu2025enhancingllmbasedshortanswer @liao2024awakening @arefeen2024leancontext 。此类方法在缓解LLM知识局限性方面具有显著优势。
Yuwei Wan等人提出了一种面向科学领域的QAG框架——SciQAG @wan2024sciqagframeworkautogeneratedscience，旨在从科学论文中自动生成高质量的问题与答案对。该框架包含一个QA生成器与一个QA评估器，二者协同工作以提升生成结果的多样性与专业性。然而，该方法在很大程度上依赖于LLM自身的知识表示能力，在面对未知或模糊信息时，生成内容的准确性和独立性仍有待提高。

尽管当前QAG方法在技术和应用层面取得了显著进展，但仍存在若干局限性，亟待进一步研究与改进。
1. 生成质量不稳定。虽然大型语言模型具备强大的语言生成能力，但其生成结果可能缺乏一致性、逻辑性或事实准确性，尤其在面对复杂语义或专业领域文本时表现不佳。
2. 低资源场景下的适用性不佳。许多基于监督学习的QAG模型需要大量人工标注的问题-答案对进行训练，而高质量标注数据的获取成本较高，难以覆盖广泛领域。
3. 知识依赖性强且可解释性差。虽然RAG等方法通过引入外部知识源提升了生成质量，但其效果高度依赖于检索系统的准确性与知识库的完整性，同时整体流程的透明度较低，难以有效追踪生成过程中的错误来源。
4. 评估机制尚不完善。目前大多数QAG系统依赖自动评价指标（如BLEU、ROUGE、BERTScore等）进行性能评估，但在衡量生成内容的语义准确性和多样性方面仍存在明显的局限。



== 研究目标&创新路径

// 本课题旨在构建一个基于RAG的QAG框架，用于自动从学术文献中提取和生成研究级别的QA对。研究内容包括：

// - 数据预处理，从UTD24中精选篇经济与管理类文章，进行文本清洗和格式化处理。
// - 构建QAG框架，利用LLM的能力，设计算法从预处理后的文献中自动提取问题和答案，生成可以用训练的高质量闭卷数据集。
// - 设计QA评估系统，构建benchmark，评估LLM在经济与管理领域的应用能力。
// - 构建实验，进行数据集质量测试和应用效果测试，在质量测试部分构建自动化评估体系和专家评估，在应用效果测试部分在已构建的benchmark上测试主流的开源和闭源大模型，并选取部分模型进行微调实验，以此测试benchmark的有效性和利用数据集进行微调对模型的提升效果。

// 最终的目标是：构建具备可视化界面，全流程自动可控，且开源易部署的QAG系统，为学术研究和实际应用提供支持。

针对当前QAG发展局限，本课题致力于突破传统数据采集范式对LLM训练的制约，构建面向专业领域的智能化数据生成体系。研究目标聚焦于以下三个维度：

1. 自动化数据生成机制创新  
   设计基于动态RAG增强的问答对生成框架（MiniRAG-QAG），通过三级递进式创新实现数据合成突破：  
   - 知识表征层：开发混合检索架构（BGE-M3+BM25+BGE-Reranker），融合语义向量与关键词检索优势，解决专业文本语义断层问题。  
   - 生成控制层：构建分层动态分块机制（段落级+内容类型级），实现代码/表格/文本的差异化处理，提升知识单元完整性。  
   - 质量保障层：建立多维度评估体系（RACAR），创新证据覆盖度量化方法与动态阈值计算模型，突破人工标注依赖瓶颈。  
2. 领域数据集构建  
   基于UTD24期刊的17542篇经管文献，构建包含170226组QA对的领域专用数据集UTD24_QA。通过"种子生成-模型微调-数据增强"的三阶段迭代策略：  
   - 学术文献结构化解析模板，实现摘要/引言/结论的精准知识抽取。  
   - 构建Alpaca兼容数据格式，支持主流LLM即插即用式微调。  
   - 配套建立benchmark评测基准，填补经管领域LLM评估体系空白。  
3. 工程化落地系统开发  
   研发模块化QAG系统，通过四大技术创新实现QA生成一体化系统：  
   - 基于Streamlit-LangChain的可视化流水线，支持文献解析/版本追溯。 
   - 元数据驱动架构实现数据血缘管理，满足医疗/金融领域合规性要求。  
   - 动态资源调度引擎，适配CPU/GPU混合计算环境。  
   - 开放式模型接入，适配多种大模型接入方式。

本研究旨在建立"数据生成-质量评估-应用落地"的完整技术闭环，探索LLM从数据依赖型向知识内生型的演进路径，为专业领域大模型训练提供开源解决方案。
